=== Federated Round 17 ===
2025-04-21 17:31:40,610 - __main__ - INFO - Starting client 0 for round 17
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:31:41,571 - utils - INFO - Partition 17/20: Using 185 of 3688 samples from preprocessed_data\client_0
2025-04-21 17:31:41,571 - utils - INFO - Found 185 valid images in preprocessed_data\client_0
2025-04-21 17:31:41,572 - utils - INFO - Loaded DataLoader from preprocessed_data\client_0 with 185 samples
2025-04-21 17:31:41,574 - __main__ - INFO - Client 0: Downloading global model
2025-04-21 17:31:42,792 - __main__ - INFO - Starting client 1 for round 17
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:31:43,809 - __main__ - INFO - Client 0: Loaded global model
2025-04-21 17:31:43,812 - __main__ - INFO - Client 0: Starting training
2025-04-21 17:31:43,813 - __main__ - INFO - Client 0: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:31:44,141 - utils - INFO - Partition 17/20: Using 186 of 3704 samples from preprocessed_data\client_1
2025-04-21 17:31:44,141 - utils - INFO - Found 186 valid images in preprocessed_data\client_1
2025-04-21 17:31:44,142 - utils - INFO - Loaded DataLoader from preprocessed_data\client_1 with 186 samples
2025-04-21 17:31:44,145 - __main__ - INFO - Client 1: Downloading global model
2025-04-21 17:31:45,385 - __main__ - INFO - Starting client 2 for round 17
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:31:46,402 - utils - INFO - Partition 17/20: Using 186 of 3701 samples from preprocessed_data\client_2
2025-04-21 17:31:46,402 - utils - INFO - Found 186 valid images in preprocessed_data\client_2
2025-04-21 17:31:46,403 - utils - INFO - Loaded DataLoader from preprocessed_data\client_2 with 186 samples
2025-04-21 17:31:46,406 - __main__ - INFO - Client 2: Downloading global model
2025-04-21 17:31:46,456 - __main__ - INFO - Client 1: Loaded global model
2025-04-21 17:31:46,460 - __main__ - INFO - Client 1: Starting training
2025-04-21 17:31:46,461 - __main__ - INFO - Client 1: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:31:48,741 - __main__ - INFO - Starting client 3 for round 17
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:31:48,809 - __main__ - INFO - Client 2: Loaded global model
2025-04-21 17:31:48,812 - __main__ - INFO - Client 2: Starting training
2025-04-21 17:31:48,813 - __main__ - INFO - Client 2: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:31:50,504 - utils - INFO - Partition 17/20: Using 185 of 3694 samples from preprocessed_data\client_3
2025-04-21 17:31:50,505 - utils - INFO - Found 185 valid images in preprocessed_data\client_3
2025-04-21 17:31:50,506 - utils - INFO - Loaded DataLoader from preprocessed_data\client_3 with 185 samples
2025-04-21 17:31:50,510 - __main__ - INFO - Client 3: Downloading global model
2025-04-21 17:31:51,349 - __main__ - INFO - Starting client 4 for round 17
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:31:51,567 - __main__ - INFO - Client 0: Completed epoch 1 with 24 batches
2025-04-21 17:31:51,567 - __main__ - INFO - Client 0: Epoch 2/10
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:31:52,385 - utils - INFO - Partition 17/20: Using 185 of 3697 samples from preprocessed_data\client_4
2025-04-21 17:31:52,386 - utils - INFO - Found 185 valid images in preprocessed_data\client_4
2025-04-21 17:31:52,387 - utils - INFO - Loaded DataLoader from preprocessed_data\client_4 with 185 samples
2025-04-21 17:31:52,391 - __main__ - INFO - Client 4: Downloading global model
2025-04-21 17:31:53,202 - __main__ - INFO - Client 3: Loaded global model
2025-04-21 17:31:53,206 - __main__ - INFO - Client 3: Starting training
2025-04-21 17:31:53,208 - __main__ - INFO - Client 3: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:31:55,432 - __main__ - INFO - Client 4: Loaded global model
2025-04-21 17:31:55,437 - __main__ - INFO - Client 4: Starting training
2025-04-21 17:31:55,439 - __main__ - INFO - Client 4: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:31:56,928 - __main__ - INFO - Client 1: Completed epoch 1 with 24 batches
2025-04-21 17:31:56,928 - __main__ - INFO - Client 1: Epoch 2/10
2025-04-21 17:32:01,910 - __main__ - INFO - Client 2: Completed epoch 1 with 24 batches
2025-04-21 17:32:01,913 - __main__ - INFO - Client 2: Epoch 2/10
2025-04-21 17:32:05,899 - __main__ - INFO - Client 0: Completed epoch 2 with 24 batches
2025-04-21 17:32:05,900 - __main__ - INFO - Client 0: Epoch 3/10
2025-04-21 17:32:10,682 - __main__ - INFO - Client 3: Completed epoch 1 with 24 batches
2025-04-21 17:32:10,683 - __main__ - INFO - Client 3: Epoch 2/10
2025-04-21 17:32:12,460 - __main__ - INFO - Client 1: Completed epoch 2 with 24 batches
2025-04-21 17:32:12,461 - __main__ - INFO - Client 1: Epoch 3/10
2025-04-21 17:32:13,100 - __main__ - INFO - Client 4: Completed epoch 1 with 24 batches
2025-04-21 17:32:13,101 - __main__ - INFO - Client 4: Epoch 2/10
2025-04-21 17:32:17,474 - __main__ - INFO - Client 2: Completed epoch 2 with 24 batches
2025-04-21 17:32:17,475 - __main__ - INFO - Client 2: Epoch 3/10
2025-04-21 17:32:21,963 - __main__ - INFO - Client 0: Completed epoch 3 with 24 batches
2025-04-21 17:32:21,964 - __main__ - INFO - Client 0: Epoch 4/10
2025-04-21 17:32:26,351 - __main__ - INFO - Client 3: Completed epoch 2 with 24 batches
2025-04-21 17:32:26,351 - __main__ - INFO - Client 3: Epoch 3/10
2025-04-21 17:32:27,916 - __main__ - INFO - Client 1: Completed epoch 3 with 24 batches
2025-04-21 17:32:27,919 - __main__ - INFO - Client 1: Epoch 4/10
2025-04-21 17:32:28,539 - __main__ - INFO - Client 4: Completed epoch 2 with 24 batches
2025-04-21 17:32:28,540 - __main__ - INFO - Client 4: Epoch 3/10
2025-04-21 17:32:32,906 - __main__ - INFO - Client 2: Completed epoch 3 with 24 batches
2025-04-21 17:32:32,907 - __main__ - INFO - Client 2: Epoch 4/10
2025-04-21 17:32:38,659 - __main__ - INFO - Client 0: Completed epoch 4 with 24 batches
2025-04-21 17:32:38,661 - __main__ - INFO - Client 0: Epoch 5/10
2025-04-21 17:32:41,799 - __main__ - INFO - Client 3: Completed epoch 3 with 24 batches
2025-04-21 17:32:41,800 - __main__ - INFO - Client 3: Epoch 4/10
2025-04-21 17:32:43,428 - __main__ - INFO - Client 1: Completed epoch 4 with 24 batches
2025-04-21 17:32:43,429 - __main__ - INFO - Client 1: Epoch 5/10
2025-04-21 17:32:43,680 - __main__ - INFO - Client 4: Completed epoch 3 with 24 batches
2025-04-21 17:32:43,680 - __main__ - INFO - Client 4: Epoch 4/10
2025-04-21 17:32:48,447 - __main__ - INFO - Client 2: Completed epoch 4 with 24 batches
2025-04-21 17:32:48,448 - __main__ - INFO - Client 2: Epoch 5/10
2025-04-21 17:32:54,542 - __main__ - INFO - Client 0: Completed epoch 5 with 24 batches
2025-04-21 17:32:54,544 - __main__ - INFO - Client 0: Epoch 6/10
2025-04-21 17:32:56,616 - __main__ - INFO - Client 3: Completed epoch 4 with 24 batches
2025-04-21 17:32:56,617 - __main__ - INFO - Client 3: Epoch 5/10
2025-04-21 17:32:58,367 - __main__ - INFO - Client 4: Completed epoch 4 with 24 batches
2025-04-21 17:32:58,368 - __main__ - INFO - Client 4: Epoch 5/10
2025-04-21 17:32:58,397 - __main__ - INFO - Client 1: Completed epoch 5 with 24 batches
2025-04-21 17:32:58,398 - __main__ - INFO - Client 1: Epoch 6/10
2025-04-21 17:33:03,716 - __main__ - INFO - Client 2: Completed epoch 5 with 24 batches
2025-04-21 17:33:03,717 - __main__ - INFO - Client 2: Epoch 6/10
2025-04-21 17:33:09,295 - __main__ - INFO - Client 0: Completed epoch 6 with 24 batches
2025-04-21 17:33:09,296 - __main__ - INFO - Client 0: Epoch 7/10
2025-04-21 17:33:11,074 - __main__ - INFO - Client 3: Completed epoch 5 with 24 batches
2025-04-21 17:33:11,074 - __main__ - INFO - Client 3: Epoch 6/10
2025-04-21 17:33:12,826 - __main__ - INFO - Client 4: Completed epoch 5 with 24 batches
2025-04-21 17:33:12,828 - __main__ - INFO - Client 4: Epoch 6/10
2025-04-21 17:33:13,406 - __main__ - INFO - Client 1: Completed epoch 6 with 24 batches
2025-04-21 17:33:13,407 - __main__ - INFO - Client 1: Epoch 7/10
2025-04-21 17:33:18,443 - __main__ - INFO - Client 2: Completed epoch 6 with 24 batches
2025-04-21 17:33:18,444 - __main__ - INFO - Client 2: Epoch 7/10
2025-04-21 17:33:24,142 - __main__ - INFO - Client 0: Completed epoch 7 with 24 batches
2025-04-21 17:33:24,142 - __main__ - INFO - Client 0: Epoch 8/10
2025-04-21 17:33:26,099 - __main__ - INFO - Client 3: Completed epoch 6 with 24 batches
2025-04-21 17:33:26,100 - __main__ - INFO - Client 3: Epoch 7/10
2025-04-21 17:33:27,660 - __main__ - INFO - Client 4: Completed epoch 6 with 24 batches
2025-04-21 17:33:27,661 - __main__ - INFO - Client 4: Epoch 7/10
2025-04-21 17:33:28,188 - __main__ - INFO - Client 1: Completed epoch 7 with 24 batches
2025-04-21 17:33:28,188 - __main__ - INFO - Client 1: Epoch 8/10
2025-04-21 17:33:33,290 - __main__ - INFO - Client 2: Completed epoch 7 with 24 batches
2025-04-21 17:33:33,292 - __main__ - INFO - Client 2: Epoch 8/10
2025-04-21 17:33:38,910 - __main__ - INFO - Client 0: Completed epoch 8 with 24 batches
2025-04-21 17:33:38,911 - __main__ - INFO - Client 0: Epoch 9/10
2025-04-21 17:33:40,786 - __main__ - INFO - Client 3: Completed epoch 7 with 24 batches
2025-04-21 17:33:40,787 - __main__ - INFO - Client 3: Epoch 8/10
2025-04-21 17:33:42,289 - __main__ - INFO - Client 4: Completed epoch 7 with 24 batches
2025-04-21 17:33:42,290 - __main__ - INFO - Client 4: Epoch 8/10
2025-04-21 17:33:42,960 - __main__ - INFO - Client 1: Completed epoch 8 with 24 batches
2025-04-21 17:33:42,961 - __main__ - INFO - Client 1: Epoch 9/10
2025-04-21 17:33:43,886 - __main__ - INFO - Client 0: Reached maximum of 200 batches in epoch 9
2025-04-21 17:33:43,886 - __main__ - INFO - Client 0: Completed epoch 9 with 8 batches
2025-04-21 17:33:43,887 - __main__ - INFO - Client 0: Reached maximum of 200 batches
2025-04-21 17:33:43,888 - __main__ - INFO - Client 0: Finished training with 200 total batches
2025-04-21 17:33:43,889 - __main__ - INFO - Client 0: Saving and sending weights
2025-04-21 17:33:46,803 - __main__ - INFO - Client 0: Weights sent to server
2025-04-21 17:33:47,338 - __main__ - INFO - Client 1: Reached maximum of 200 batches in epoch 9
2025-04-21 17:33:47,339 - __main__ - INFO - Client 1: Completed epoch 9 with 8 batches
2025-04-21 17:33:47,340 - __main__ - INFO - Client 1: Reached maximum of 200 batches
2025-04-21 17:33:47,341 - __main__ - INFO - Client 1: Finished training with 200 total batches
2025-04-21 17:33:47,341 - __main__ - INFO - Client 1: Saving and sending weights
2025-04-21 17:33:47,383 - __main__ - INFO - Client 2: Completed epoch 8 with 24 batches
2025-04-21 17:33:47,385 - __main__ - INFO - Client 2: Epoch 9/10
2025-04-21 17:33:50,101 - __main__ - INFO - Client 1: Weights sent to server
2025-04-21 17:33:50,606 - __main__ - INFO - Client 2: Reached maximum of 200 batches in epoch 9
2025-04-21 17:33:50,607 - __main__ - INFO - Client 2: Completed epoch 9 with 8 batches
2025-04-21 17:33:50,609 - __main__ - INFO - Client 2: Reached maximum of 200 batches
2025-04-21 17:33:50,610 - __main__ - INFO - Client 2: Finished training with 200 total batches
2025-04-21 17:33:50,610 - __main__ - INFO - Client 2: Saving and sending weights
2025-04-21 17:33:51,657 - __main__ - INFO - Client 3: Completed epoch 8 with 24 batches
2025-04-21 17:33:51,657 - __main__ - INFO - Client 3: Epoch 9/10
2025-04-21 17:33:52,370 - __main__ - INFO - Client 4: Completed epoch 8 with 24 batches
2025-04-21 17:33:52,371 - __main__ - INFO - Client 4: Epoch 9/10
2025-04-21 17:33:53,187 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:33:54,158 - __main__ - INFO - Client 3: Reached maximum of 200 batches in epoch 9
2025-04-21 17:33:54,158 - __main__ - INFO - Client 3: Completed epoch 9 with 8 batches
2025-04-21 17:33:54,159 - __main__ - INFO - Client 3: Reached maximum of 200 batches
2025-04-21 17:33:54,159 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:33:54,159 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:33:54,708 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:33:54,708 - __main__ - INFO - Client 4: Completed epoch 9 with 8 batches
2025-04-21 17:33:54,708 - __main__ - INFO - Client 4: Reached maximum of 200 batches
2025-04-21 17:33:54,708 - __main__ - INFO - Client 4: Finished training with 200 total batches
2025-04-21 17:33:54,709 - __main__ - INFO - Client 4: Saving and sending weights
2025-04-21 17:33:56,581 - __main__ - INFO - Client 3: Weights sent to server
2025-04-21 17:33:57,075 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:34:00,949 - __main__ - INFO - Starting nightly aggregation...
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:34:02,321 - __main__ - INFO - Found 5 client weights for aggregation
2025-04-21 17:34:08,659 - __main__ - INFO - Processed weights from weights_0_20250421_173346.h5 with 185 samples
2025-04-21 17:34:08,668 - __main__ - INFO - Processed weights from weights_1_20250421_173350.h5 with 186 samples
2025-04-21 17:34:08,676 - __main__ - INFO - Processed weights from weights_2_20250421_173353.h5 with 186 samples
2025-04-21 17:34:08,684 - __main__ - INFO - Processed weights from weights_3_20250421_173356.h5 with 185 samples
2025-04-21 17:34:08,691 - __main__ - INFO - Processed weights from weights_4_20250421_173357.h5 with 185 samples
2025-04-21 17:34:08,795 - __main__ - INFO - Aggregated and saved global model to global_model.h5
2025-04-21 17:34:08,798 - __main__ - INFO - Archived processed weight files
Validation: {'loss': 5.821438933610916, 'accuracy': 3.9692701664532652}

=== Federated Round 18 ===
2025-04-21 17:34:27,659 - __main__ - INFO - Starting client 0 for round 18
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:34:28,733 - utils - INFO - Partition 18/20: Using 185 of 3688 samples from preprocessed_data\client_0
2025-04-21 17:34:28,733 - utils - INFO - Found 185 valid images in preprocessed_data\client_0
2025-04-21 17:34:28,734 - utils - INFO - Loaded DataLoader from preprocessed_data\client_0 with 185 samples
2025-04-21 17:34:28,736 - __main__ - INFO - Client 0: Downloading global model
2025-04-21 17:34:29,769 - __main__ - INFO - Starting client 1 for round 18
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:34:30,921 - utils - INFO - Partition 18/20: Using 186 of 3704 samples from preprocessed_data\client_1
2025-04-21 17:34:30,921 - utils - INFO - Found 186 valid images in preprocessed_data\client_1
2025-04-21 17:34:30,922 - utils - INFO - Loaded DataLoader from preprocessed_data\client_1 with 186 samples
2025-04-21 17:34:30,925 - __main__ - INFO - Client 1: Downloading global model
2025-04-21 17:34:30,992 - __main__ - INFO - Client 0: Loaded global model
2025-04-21 17:34:30,995 - __main__ - INFO - Client 0: Starting training
2025-04-21 17:34:30,996 - __main__ - INFO - Client 0: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:34:32,242 - __main__ - INFO - Starting client 2 for round 18
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:34:33,215 - __main__ - INFO - Client 1: Loaded global model
2025-04-21 17:34:33,219 - __main__ - INFO - Client 1: Starting training
2025-04-21 17:34:33,220 - __main__ - INFO - Client 1: Epoch 1/10
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:34:33,256 - utils - INFO - Partition 18/20: Using 186 of 3701 samples from preprocessed_data\client_2
2025-04-21 17:34:33,257 - utils - INFO - Found 186 valid images in preprocessed_data\client_2
2025-04-21 17:34:33,258 - utils - INFO - Loaded DataLoader from preprocessed_data\client_2 with 186 samples
2025-04-21 17:34:33,261 - __main__ - INFO - Client 2: Downloading global model
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:34:35,532 - __main__ - INFO - Starting client 3 for round 18
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:34:35,659 - __main__ - INFO - Client 2: Loaded global model
2025-04-21 17:34:35,663 - __main__ - INFO - Client 2: Starting training
2025-04-21 17:34:35,664 - __main__ - INFO - Client 2: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:34:37,110 - utils - INFO - Partition 18/20: Using 185 of 3694 samples from preprocessed_data\client_3
2025-04-21 17:34:37,111 - utils - INFO - Found 185 valid images in preprocessed_data\client_3
2025-04-21 17:34:37,112 - utils - INFO - Loaded DataLoader from preprocessed_data\client_3 with 185 samples
2025-04-21 17:34:37,115 - __main__ - INFO - Client 3: Downloading global model
2025-04-21 17:34:38,353 - __main__ - INFO - Starting client 4 for round 18
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:34:38,506 - __main__ - INFO - Client 0: Completed epoch 1 with 24 batches
2025-04-21 17:34:38,506 - __main__ - INFO - Client 0: Epoch 2/10
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:34:39,402 - utils - INFO - Partition 18/20: Using 185 of 3697 samples from preprocessed_data\client_4
2025-04-21 17:34:39,403 - utils - INFO - Found 185 valid images in preprocessed_data\client_4
2025-04-21 17:34:39,404 - utils - INFO - Loaded DataLoader from preprocessed_data\client_4 with 185 samples
2025-04-21 17:34:39,410 - __main__ - INFO - Client 4: Downloading global model
2025-04-21 17:34:39,703 - __main__ - INFO - Client 3: Loaded global model
2025-04-21 17:34:39,707 - __main__ - INFO - Client 3: Starting training
2025-04-21 17:34:39,709 - __main__ - INFO - Client 3: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:34:42,124 - __main__ - INFO - Client 4: Loaded global model
2025-04-21 17:34:42,129 - __main__ - INFO - Client 4: Starting training
2025-04-21 17:34:42,132 - __main__ - INFO - Client 4: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:34:44,203 - __main__ - INFO - Client 1: Completed epoch 1 with 24 batches
2025-04-21 17:34:44,206 - __main__ - INFO - Client 1: Epoch 2/10
2025-04-21 17:34:48,249 - __main__ - INFO - Client 2: Completed epoch 1 with 24 batches
2025-04-21 17:34:48,250 - __main__ - INFO - Client 2: Epoch 2/10
2025-04-21 17:34:52,602 - __main__ - INFO - Client 0: Completed epoch 2 with 24 batches
2025-04-21 17:34:52,603 - __main__ - INFO - Client 0: Epoch 3/10
2025-04-21 17:34:56,265 - __main__ - INFO - Client 3: Completed epoch 1 with 24 batches
2025-04-21 17:34:56,266 - __main__ - INFO - Client 3: Epoch 2/10
2025-04-21 17:34:59,201 - __main__ - INFO - Client 1: Completed epoch 2 with 24 batches
2025-04-21 17:34:59,202 - __main__ - INFO - Client 1: Epoch 3/10
2025-04-21 17:34:59,506 - __main__ - INFO - Client 4: Completed epoch 1 with 24 batches
2025-04-21 17:34:59,507 - __main__ - INFO - Client 4: Epoch 2/10
2025-04-21 17:35:02,893 - __main__ - INFO - Client 2: Completed epoch 2 with 24 batches
2025-04-21 17:35:02,894 - __main__ - INFO - Client 2: Epoch 3/10
2025-04-21 17:35:07,307 - __main__ - INFO - Client 0: Completed epoch 3 with 24 batches
2025-04-21 17:35:07,308 - __main__ - INFO - Client 0: Epoch 4/10
2025-04-21 17:35:11,138 - __main__ - INFO - Client 3: Completed epoch 2 with 24 batches
2025-04-21 17:35:11,139 - __main__ - INFO - Client 3: Epoch 3/10
2025-04-21 17:35:13,876 - __main__ - INFO - Client 1: Completed epoch 3 with 24 batches
2025-04-21 17:35:13,876 - __main__ - INFO - Client 1: Epoch 4/10
2025-04-21 17:35:14,382 - __main__ - INFO - Client 4: Completed epoch 2 with 24 batches
2025-04-21 17:35:14,382 - __main__ - INFO - Client 4: Epoch 3/10
2025-04-21 17:35:17,454 - __main__ - INFO - Client 2: Completed epoch 3 with 24 batches
2025-04-21 17:35:17,458 - __main__ - INFO - Client 2: Epoch 4/10
2025-04-21 17:35:22,062 - __main__ - INFO - Client 0: Completed epoch 4 with 24 batches
2025-04-21 17:35:22,064 - __main__ - INFO - Client 0: Epoch 5/10
2025-04-21 17:35:25,940 - __main__ - INFO - Client 3: Completed epoch 3 with 24 batches
2025-04-21 17:35:25,941 - __main__ - INFO - Client 3: Epoch 4/10
2025-04-21 17:35:28,414 - __main__ - INFO - Client 1: Completed epoch 4 with 24 batches
2025-04-21 17:35:28,416 - __main__ - INFO - Client 1: Epoch 5/10
2025-04-21 17:35:28,911 - __main__ - INFO - Client 4: Completed epoch 3 with 24 batches
2025-04-21 17:35:28,912 - __main__ - INFO - Client 4: Epoch 4/10
2025-04-21 17:35:32,414 - __main__ - INFO - Client 2: Completed epoch 4 with 24 batches
2025-04-21 17:35:32,415 - __main__ - INFO - Client 2: Epoch 5/10
2025-04-21 17:35:36,951 - __main__ - INFO - Client 0: Completed epoch 5 with 24 batches
2025-04-21 17:35:36,952 - __main__ - INFO - Client 0: Epoch 6/10
2025-04-21 17:35:40,463 - __main__ - INFO - Client 3: Completed epoch 4 with 24 batches
2025-04-21 17:35:40,464 - __main__ - INFO - Client 3: Epoch 5/10
2025-04-21 17:35:43,323 - __main__ - INFO - Client 1: Completed epoch 5 with 24 batches
2025-04-21 17:35:43,324 - __main__ - INFO - Client 1: Epoch 6/10
2025-04-21 17:35:43,482 - __main__ - INFO - Client 4: Completed epoch 4 with 24 batches
2025-04-21 17:35:43,482 - __main__ - INFO - Client 4: Epoch 5/10
2025-04-21 17:35:47,200 - __main__ - INFO - Client 2: Completed epoch 5 with 24 batches
2025-04-21 17:35:47,201 - __main__ - INFO - Client 2: Epoch 6/10
2025-04-21 17:35:51,472 - __main__ - INFO - Client 0: Completed epoch 6 with 24 batches
2025-04-21 17:35:51,473 - __main__ - INFO - Client 0: Epoch 7/10
2025-04-21 17:35:55,219 - __main__ - INFO - Client 3: Completed epoch 5 with 24 batches
2025-04-21 17:35:55,220 - __main__ - INFO - Client 3: Epoch 6/10
2025-04-21 17:35:58,121 - __main__ - INFO - Client 1: Completed epoch 6 with 24 batches
2025-04-21 17:35:58,122 - __main__ - INFO - Client 1: Epoch 7/10
2025-04-21 17:35:58,497 - __main__ - INFO - Client 4: Completed epoch 5 with 24 batches
2025-04-21 17:35:58,499 - __main__ - INFO - Client 4: Epoch 6/10
2025-04-21 17:36:01,742 - __main__ - INFO - Client 2: Completed epoch 6 with 24 batches
2025-04-21 17:36:01,742 - __main__ - INFO - Client 2: Epoch 7/10
2025-04-21 17:36:06,026 - __main__ - INFO - Client 0: Completed epoch 7 with 24 batches
2025-04-21 17:36:06,029 - __main__ - INFO - Client 0: Epoch 8/10
2025-04-21 17:36:09,854 - __main__ - INFO - Client 3: Completed epoch 6 with 24 batches
2025-04-21 17:36:09,854 - __main__ - INFO - Client 3: Epoch 7/10
2025-04-21 17:36:12,721 - __main__ - INFO - Client 1: Completed epoch 7 with 24 batches
2025-04-21 17:36:12,721 - __main__ - INFO - Client 1: Epoch 8/10
2025-04-21 17:36:13,266 - __main__ - INFO - Client 4: Completed epoch 6 with 24 batches
2025-04-21 17:36:13,267 - __main__ - INFO - Client 4: Epoch 7/10
2025-04-21 17:36:16,743 - __main__ - INFO - Client 2: Completed epoch 7 with 24 batches
2025-04-21 17:36:16,745 - __main__ - INFO - Client 2: Epoch 8/10
2025-04-21 17:36:20,763 - __main__ - INFO - Client 0: Completed epoch 8 with 24 batches
2025-04-21 17:36:20,764 - __main__ - INFO - Client 0: Epoch 9/10
2025-04-21 17:36:24,534 - __main__ - INFO - Client 3: Completed epoch 7 with 24 batches
2025-04-21 17:36:24,537 - __main__ - INFO - Client 3: Epoch 8/10
2025-04-21 17:36:25,816 - __main__ - INFO - Client 0: Reached maximum of 200 batches in epoch 9
2025-04-21 17:36:25,817 - __main__ - INFO - Client 0: Completed epoch 9 with 8 batches
2025-04-21 17:36:25,819 - __main__ - INFO - Client 0: Reached maximum of 200 batches
2025-04-21 17:36:25,820 - __main__ - INFO - Client 0: Finished training with 200 total batches
2025-04-21 17:36:25,820 - __main__ - INFO - Client 0: Saving and sending weights
2025-04-21 17:36:26,965 - __main__ - INFO - Client 1: Completed epoch 8 with 24 batches
2025-04-21 17:36:26,966 - __main__ - INFO - Client 1: Epoch 9/10
2025-04-21 17:36:27,379 - __main__ - INFO - Client 4: Completed epoch 7 with 24 batches
2025-04-21 17:36:27,379 - __main__ - INFO - Client 4: Epoch 8/10
2025-04-21 17:36:28,613 - __main__ - INFO - Client 0: Weights sent to server
2025-04-21 17:36:30,678 - __main__ - INFO - Client 2: Completed epoch 8 with 24 batches
2025-04-21 17:36:30,679 - __main__ - INFO - Client 2: Epoch 9/10
2025-04-21 17:36:31,147 - __main__ - INFO - Client 1: Reached maximum of 200 batches in epoch 9
2025-04-21 17:36:31,147 - __main__ - INFO - Client 1: Completed epoch 9 with 8 batches
2025-04-21 17:36:31,147 - __main__ - INFO - Client 1: Reached maximum of 200 batches
2025-04-21 17:36:31,148 - __main__ - INFO - Client 1: Finished training with 200 total batches
2025-04-21 17:36:31,148 - __main__ - INFO - Client 1: Saving and sending weights
2025-04-21 17:36:33,907 - __main__ - INFO - Client 1: Weights sent to server
2025-04-21 17:36:34,129 - __main__ - INFO - Client 2: Reached maximum of 200 batches in epoch 9
2025-04-21 17:36:34,129 - __main__ - INFO - Client 2: Completed epoch 9 with 8 batches
2025-04-21 17:36:34,130 - __main__ - INFO - Client 2: Reached maximum of 200 batches
2025-04-21 17:36:34,132 - __main__ - INFO - Client 2: Finished training with 200 total batches
2025-04-21 17:36:34,133 - __main__ - INFO - Client 2: Saving and sending weights
2025-04-21 17:36:35,200 - __main__ - INFO - Client 3: Completed epoch 8 with 24 batches
2025-04-21 17:36:35,201 - __main__ - INFO - Client 3: Epoch 9/10
2025-04-21 17:36:36,597 - __main__ - INFO - Client 4: Completed epoch 8 with 24 batches
2025-04-21 17:36:36,598 - __main__ - INFO - Client 4: Epoch 9/10
2025-04-21 17:36:36,890 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:36:37,600 - __main__ - INFO - Client 3: Reached maximum of 200 batches in epoch 9
2025-04-21 17:36:37,601 - __main__ - INFO - Client 3: Completed epoch 9 with 8 batches
2025-04-21 17:36:37,601 - __main__ - INFO - Client 3: Reached maximum of 200 batches
2025-04-21 17:36:37,601 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:36:37,601 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:36:38,615 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:36:38,616 - __main__ - INFO - Client 4: Completed epoch 9 with 8 batches
2025-04-21 17:36:38,616 - __main__ - INFO - Client 4: Reached maximum of 200 batches
2025-04-21 17:36:38,616 - __main__ - INFO - Client 4: Finished training with 200 total batches
2025-04-21 17:36:38,616 - __main__ - INFO - Client 4: Saving and sending weights
2025-04-21 17:36:40,081 - __main__ - INFO - Client 3: Weights sent to server
2025-04-21 17:36:40,883 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:36:44,735 - __main__ - INFO - Starting nightly aggregation...
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:36:45,860 - __main__ - INFO - Found 5 client weights for aggregation
2025-04-21 17:36:52,260 - __main__ - INFO - Processed weights from weights_0_20250421_173628.h5 with 185 samples
2025-04-21 17:36:52,268 - __main__ - INFO - Processed weights from weights_1_20250421_173633.h5 with 186 samples
2025-04-21 17:36:52,275 - __main__ - INFO - Processed weights from weights_2_20250421_173636.h5 with 186 samples
2025-04-21 17:36:52,283 - __main__ - INFO - Processed weights from weights_3_20250421_173640.h5 with 185 samples
2025-04-21 17:36:52,291 - __main__ - INFO - Processed weights from weights_4_20250421_173640.h5 with 185 samples
2025-04-21 17:36:52,411 - __main__ - INFO - Aggregated and saved global model to global_model.h5
2025-04-21 17:36:52,414 - __main__ - INFO - Archived processed weight files
Validation: {'loss': 1.6116393673419953, 'accuracy': 46.60691421254801}

=== Federated Round 19 ===
2025-04-21 17:37:11,367 - __main__ - INFO - Starting client 0 for round 19
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:37:12,310 - utils - INFO - Partition 19/20: Using 185 of 3688 samples from preprocessed_data\client_0
2025-04-21 17:37:12,310 - utils - INFO - Found 185 valid images in preprocessed_data\client_0
2025-04-21 17:37:12,311 - utils - INFO - Loaded DataLoader from preprocessed_data\client_0 with 185 samples
2025-04-21 17:37:12,313 - __main__ - INFO - Client 0: Downloading global model
2025-04-21 17:37:13,492 - __main__ - INFO - Starting client 1 for round 19
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:37:14,540 - __main__ - INFO - Client 0: Loaded global model
2025-04-21 17:37:14,543 - __main__ - INFO - Client 0: Starting training
2025-04-21 17:37:14,544 - __main__ - INFO - Client 0: Epoch 1/10
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:37:14,570 - utils - INFO - Partition 19/20: Using 186 of 3704 samples from preprocessed_data\client_1
2025-04-21 17:37:14,570 - utils - INFO - Found 186 valid images in preprocessed_data\client_1
2025-04-21 17:37:14,571 - utils - INFO - Loaded DataLoader from preprocessed_data\client_1 with 186 samples
2025-04-21 17:37:14,574 - __main__ - INFO - Client 1: Downloading global model
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:37:15,972 - __main__ - INFO - Starting client 2 for round 19
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:37:16,870 - __main__ - INFO - Client 1: Loaded global model
2025-04-21 17:37:16,874 - __main__ - INFO - Client 1: Starting training
2025-04-21 17:37:16,876 - __main__ - INFO - Client 1: Epoch 1/10
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:37:16,974 - utils - INFO - Partition 19/20: Using 186 of 3701 samples from preprocessed_data\client_2
2025-04-21 17:37:16,976 - utils - INFO - Found 186 valid images in preprocessed_data\client_2
2025-04-21 17:37:16,978 - utils - INFO - Loaded DataLoader from preprocessed_data\client_2 with 186 samples
2025-04-21 17:37:16,982 - __main__ - INFO - Client 2: Downloading global model
2025-04-21 17:37:19,357 - __main__ - INFO - Starting client 3 for round 19
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:37:19,387 - __main__ - INFO - Client 2: Loaded global model
2025-04-21 17:37:19,391 - __main__ - INFO - Client 2: Starting training
2025-04-21 17:37:19,392 - __main__ - INFO - Client 2: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:37:20,341 - utils - INFO - Partition 19/20: Using 185 of 3694 samples from preprocessed_data\client_3
2025-04-21 17:37:20,342 - utils - INFO - Found 185 valid images in preprocessed_data\client_3
2025-04-21 17:37:20,344 - utils - INFO - Loaded DataLoader from preprocessed_data\client_3 with 185 samples
2025-04-21 17:37:20,350 - __main__ - INFO - Client 3: Downloading global model
2025-04-21 17:37:21,770 - __main__ - INFO - Client 0: Completed epoch 1 with 24 batches
2025-04-21 17:37:21,771 - __main__ - INFO - Client 0: Epoch 2/10
2025-04-21 17:37:22,201 - __main__ - INFO - Starting client 4 for round 19
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:37:23,190 - __main__ - INFO - Client 3: Loaded global model
2025-04-21 17:37:23,195 - __main__ - INFO - Client 3: Starting training
2025-04-21 17:37:23,197 - __main__ - INFO - Client 3: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:37:23,335 - utils - INFO - Partition 19/20: Using 185 of 3697 samples from preprocessed_data\client_4
2025-04-21 17:37:23,336 - utils - INFO - Found 185 valid images in preprocessed_data\client_4
2025-04-21 17:37:23,337 - utils - INFO - Loaded DataLoader from preprocessed_data\client_4 with 185 samples
2025-04-21 17:37:23,342 - __main__ - INFO - Client 4: Downloading global model
2025-04-21 17:37:26,094 - __main__ - INFO - Client 4: Loaded global model
2025-04-21 17:37:26,098 - __main__ - INFO - Client 4: Starting training
2025-04-21 17:37:26,100 - __main__ - INFO - Client 4: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:37:28,467 - __main__ - INFO - Client 1: Completed epoch 1 with 24 batches
2025-04-21 17:37:28,467 - __main__ - INFO - Client 1: Epoch 2/10
2025-04-21 17:37:31,943 - __main__ - INFO - Client 2: Completed epoch 1 with 24 batches
2025-04-21 17:37:31,945 - __main__ - INFO - Client 2: Epoch 2/10
2025-04-21 17:37:35,684 - __main__ - INFO - Client 0: Completed epoch 2 with 24 batches
2025-04-21 17:37:35,685 - __main__ - INFO - Client 0: Epoch 3/10
2025-04-21 17:37:37,553 - __main__ - INFO - Client 3: Completed epoch 1 with 24 batches
2025-04-21 17:37:37,553 - __main__ - INFO - Client 3: Epoch 2/10
2025-04-21 17:37:43,944 - __main__ - INFO - Client 4: Completed epoch 1 with 24 batches
2025-04-21 17:37:43,945 - __main__ - INFO - Client 4: Epoch 2/10
2025-04-21 17:37:44,153 - __main__ - INFO - Client 1: Completed epoch 2 with 24 batches
2025-04-21 17:37:44,154 - __main__ - INFO - Client 1: Epoch 3/10
2025-04-21 17:37:46,506 - __main__ - INFO - Client 2: Completed epoch 2 with 24 batches
2025-04-21 17:37:46,508 - __main__ - INFO - Client 2: Epoch 3/10
2025-04-21 17:37:50,076 - __main__ - INFO - Client 0: Completed epoch 3 with 24 batches
2025-04-21 17:37:50,076 - __main__ - INFO - Client 0: Epoch 4/10
2025-04-21 17:37:51,947 - __main__ - INFO - Client 3: Completed epoch 2 with 24 batches
2025-04-21 17:37:51,948 - __main__ - INFO - Client 3: Epoch 3/10
2025-04-21 17:37:58,823 - __main__ - INFO - Client 4: Completed epoch 2 with 24 batches
2025-04-21 17:37:58,824 - __main__ - INFO - Client 4: Epoch 3/10
2025-04-21 17:38:00,118 - __main__ - INFO - Client 1: Completed epoch 3 with 24 batches
2025-04-21 17:38:00,119 - __main__ - INFO - Client 1: Epoch 4/10
2025-04-21 17:38:00,964 - __main__ - INFO - Client 2: Completed epoch 3 with 24 batches
2025-04-21 17:38:00,964 - __main__ - INFO - Client 2: Epoch 4/10
2025-04-21 17:38:04,556 - __main__ - INFO - Client 0: Completed epoch 4 with 24 batches
2025-04-21 17:38:04,556 - __main__ - INFO - Client 0: Epoch 5/10
2025-04-21 17:38:06,433 - __main__ - INFO - Client 3: Completed epoch 3 with 24 batches
2025-04-21 17:38:06,434 - __main__ - INFO - Client 3: Epoch 4/10
2025-04-21 17:38:13,222 - __main__ - INFO - Client 4: Completed epoch 3 with 24 batches
2025-04-21 17:38:13,223 - __main__ - INFO - Client 4: Epoch 4/10
2025-04-21 17:38:15,639 - __main__ - INFO - Client 1: Completed epoch 4 with 24 batches
2025-04-21 17:38:15,640 - __main__ - INFO - Client 1: Epoch 5/10
2025-04-21 17:38:15,829 - __main__ - INFO - Client 2: Completed epoch 4 with 24 batches
2025-04-21 17:38:15,829 - __main__ - INFO - Client 2: Epoch 5/10
2025-04-21 17:38:19,083 - __main__ - INFO - Client 0: Completed epoch 5 with 24 batches
2025-04-21 17:38:19,084 - __main__ - INFO - Client 0: Epoch 6/10
2025-04-21 17:38:20,950 - __main__ - INFO - Client 3: Completed epoch 4 with 24 batches
2025-04-21 17:38:20,950 - __main__ - INFO - Client 3: Epoch 5/10
2025-04-21 17:38:28,359 - __main__ - INFO - Client 4: Completed epoch 4 with 24 batches
2025-04-21 17:38:28,361 - __main__ - INFO - Client 4: Epoch 5/10
2025-04-21 17:38:30,906 - __main__ - INFO - Client 1: Completed epoch 5 with 24 batches
2025-04-21 17:38:30,906 - __main__ - INFO - Client 1: Epoch 6/10
2025-04-21 17:38:30,969 - __main__ - INFO - Client 2: Completed epoch 5 with 24 batches
2025-04-21 17:38:30,969 - __main__ - INFO - Client 2: Epoch 6/10
2025-04-21 17:38:34,103 - __main__ - INFO - Client 0: Completed epoch 6 with 24 batches
2025-04-21 17:38:34,104 - __main__ - INFO - Client 0: Epoch 7/10
2025-04-21 17:38:35,999 - __main__ - INFO - Client 3: Completed epoch 5 with 24 batches
2025-04-21 17:38:35,999 - __main__ - INFO - Client 3: Epoch 6/10
2025-04-21 17:38:43,056 - __main__ - INFO - Client 4: Completed epoch 5 with 24 batches
2025-04-21 17:38:43,057 - __main__ - INFO - Client 4: Epoch 6/10
2025-04-21 17:38:45,544 - __main__ - INFO - Client 2: Completed epoch 6 with 24 batches
2025-04-21 17:38:45,544 - __main__ - INFO - Client 2: Epoch 7/10
2025-04-21 17:38:46,423 - __main__ - INFO - Client 1: Completed epoch 6 with 24 batches
2025-04-21 17:38:46,424 - __main__ - INFO - Client 1: Epoch 7/10
2025-04-21 17:38:48,609 - __main__ - INFO - Client 0: Completed epoch 7 with 24 batches
2025-04-21 17:38:48,610 - __main__ - INFO - Client 0: Epoch 8/10
2025-04-21 17:38:50,523 - __main__ - INFO - Client 3: Completed epoch 6 with 24 batches
2025-04-21 17:38:50,524 - __main__ - INFO - Client 3: Epoch 7/10
2025-04-21 17:38:57,560 - __main__ - INFO - Client 4: Completed epoch 6 with 24 batches
2025-04-21 17:38:57,560 - __main__ - INFO - Client 4: Epoch 7/10
2025-04-21 17:39:00,099 - __main__ - INFO - Client 2: Completed epoch 7 with 24 batches
2025-04-21 17:39:00,099 - __main__ - INFO - Client 2: Epoch 8/10
2025-04-21 17:39:01,907 - __main__ - INFO - Client 1: Completed epoch 7 with 24 batches
2025-04-21 17:39:01,907 - __main__ - INFO - Client 1: Epoch 8/10
2025-04-21 17:39:03,150 - __main__ - INFO - Client 0: Completed epoch 8 with 24 batches
2025-04-21 17:39:03,150 - __main__ - INFO - Client 0: Epoch 9/10
2025-04-21 17:39:05,320 - __main__ - INFO - Client 3: Completed epoch 7 with 24 batches
2025-04-21 17:39:05,321 - __main__ - INFO - Client 3: Epoch 8/10
2025-04-21 17:39:08,316 - __main__ - INFO - Client 0: Reached maximum of 200 batches in epoch 9
2025-04-21 17:39:08,317 - __main__ - INFO - Client 0: Completed epoch 9 with 8 batches
2025-04-21 17:39:08,318 - __main__ - INFO - Client 0: Reached maximum of 200 batches
2025-04-21 17:39:08,319 - __main__ - INFO - Client 0: Finished training with 200 total batches
2025-04-21 17:39:08,319 - __main__ - INFO - Client 0: Saving and sending weights
2025-04-21 17:39:11,279 - __main__ - INFO - Client 0: Weights sent to server
2025-04-21 17:39:11,488 - __main__ - INFO - Client 4: Completed epoch 7 with 24 batches
2025-04-21 17:39:11,488 - __main__ - INFO - Client 4: Epoch 8/10
2025-04-21 17:39:13,550 - __main__ - INFO - Client 2: Completed epoch 8 with 24 batches
2025-04-21 17:39:13,551 - __main__ - INFO - Client 2: Epoch 9/10
2025-04-21 17:39:15,310 - __main__ - INFO - Client 1: Completed epoch 8 with 24 batches
2025-04-21 17:39:15,311 - __main__ - INFO - Client 1: Epoch 9/10
2025-04-21 17:39:17,602 - __main__ - INFO - Client 2: Reached maximum of 200 batches in epoch 9
2025-04-21 17:39:17,603 - __main__ - INFO - Client 2: Completed epoch 9 with 8 batches
2025-04-21 17:39:17,604 - __main__ - INFO - Client 2: Reached maximum of 200 batches
2025-04-21 17:39:17,605 - __main__ - INFO - Client 2: Finished training with 200 total batches
2025-04-21 17:39:17,606 - __main__ - INFO - Client 2: Saving and sending weights
2025-04-21 17:39:17,931 - __main__ - INFO - Client 3: Completed epoch 8 with 24 batches
2025-04-21 17:39:17,931 - __main__ - INFO - Client 3: Epoch 9/10
2025-04-21 17:39:19,000 - __main__ - INFO - Client 1: Reached maximum of 200 batches in epoch 9
2025-04-21 17:39:19,000 - __main__ - INFO - Client 1: Completed epoch 9 with 8 batches
2025-04-21 17:39:19,000 - __main__ - INFO - Client 1: Reached maximum of 200 batches
2025-04-21 17:39:19,001 - __main__ - INFO - Client 1: Finished training with 200 total batches
2025-04-21 17:39:19,002 - __main__ - INFO - Client 1: Saving and sending weights
2025-04-21 17:39:20,472 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:39:20,630 - __main__ - INFO - Client 3: Reached maximum of 200 batches in epoch 9
2025-04-21 17:39:20,630 - __main__ - INFO - Client 3: Completed epoch 9 with 8 batches
2025-04-21 17:39:20,631 - __main__ - INFO - Client 3: Reached maximum of 200 batches
2025-04-21 17:39:20,631 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:39:20,631 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:39:21,144 - __main__ - INFO - Client 4: Completed epoch 8 with 24 batches
2025-04-21 17:39:21,144 - __main__ - INFO - Client 4: Epoch 9/10
2025-04-21 17:39:21,558 - __main__ - INFO - Client 1: Weights sent to server
2025-04-21 17:39:22,807 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:39:22,808 - __main__ - INFO - Client 4: Completed epoch 9 with 8 batches
2025-04-21 17:39:22,808 - __main__ - INFO - Client 4: Reached maximum of 200 batches
2025-04-21 17:39:22,808 - __main__ - INFO - Client 4: Finished training with 200 total batches
2025-04-21 17:39:22,809 - __main__ - INFO - Client 4: Saving and sending weights
2025-04-21 17:39:23,115 - __main__ - INFO - Client 3: Weights sent to server
2025-04-21 17:39:25,175 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:39:29,069 - __main__ - INFO - Starting nightly aggregation...
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:39:30,108 - __main__ - INFO - Found 5 client weights for aggregation
2025-04-21 17:39:36,584 - __main__ - INFO - Processed weights from weights_0_20250421_173911.h5 with 185 samples
2025-04-21 17:39:36,592 - __main__ - INFO - Processed weights from weights_1_20250421_173921.h5 with 186 samples
2025-04-21 17:39:36,599 - __main__ - INFO - Processed weights from weights_2_20250421_173920.h5 with 186 samples
2025-04-21 17:39:36,607 - __main__ - INFO - Processed weights from weights_3_20250421_173923.h5 with 185 samples
2025-04-21 17:39:36,615 - __main__ - INFO - Processed weights from weights_4_20250421_173925.h5 with 185 samples
2025-04-21 17:39:36,730 - __main__ - INFO - Aggregated and saved global model to global_model.h5
2025-04-21 17:39:36,732 - __main__ - INFO - Archived processed weight files
Validation: {'loss': 1.8765527312178165, 'accuracy': 67.3495518565941}

=== Federated Round 20 ===
2025-04-21 17:39:55,464 - __main__ - INFO - Starting client 0 for round 20
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:39:56,638 - utils - INFO - Partition 20/20: Using 173 of 3688 samples from preprocessed_data\client_0
2025-04-21 17:39:56,639 - utils - INFO - Found 173 valid images in preprocessed_data\client_0
2025-04-21 17:39:56,639 - utils - INFO - Loaded DataLoader from preprocessed_data\client_0 with 173 samples
2025-04-21 17:39:56,642 - __main__ - INFO - Client 0: Downloading global model
2025-04-21 17:39:57,570 - __main__ - INFO - Starting client 1 for round 20
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:39:58,589 - utils - INFO - Partition 20/20: Using 170 of 3704 samples from preprocessed_data\client_1
2025-04-21 17:39:58,589 - utils - INFO - Found 170 valid images in preprocessed_data\client_1
2025-04-21 17:39:58,590 - utils - INFO - Loaded DataLoader from preprocessed_data\client_1 with 170 samples
2025-04-21 17:39:58,593 - __main__ - INFO - Client 1: Downloading global model
2025-04-21 17:39:58,851 - __main__ - INFO - Client 0: Loaded global model
2025-04-21 17:39:58,854 - __main__ - INFO - Client 0: Starting training
2025-04-21 17:39:58,854 - __main__ - INFO - Client 0: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:40:00,022 - __main__ - INFO - Starting client 2 for round 20
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:40:00,891 - __main__ - INFO - Client 1: Loaded global model
2025-04-21 17:40:00,894 - __main__ - INFO - Client 1: Starting training
2025-04-21 17:40:00,895 - __main__ - INFO - Client 1: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:40:01,216 - utils - INFO - Partition 20/20: Using 167 of 3701 samples from preprocessed_data\client_2
2025-04-21 17:40:01,216 - utils - INFO - Found 167 valid images in preprocessed_data\client_2
2025-04-21 17:40:01,217 - utils - INFO - Loaded DataLoader from preprocessed_data\client_2 with 167 samples
2025-04-21 17:40:01,220 - __main__ - INFO - Client 2: Downloading global model
2025-04-21 17:40:03,506 - __main__ - INFO - Starting client 3 for round 20
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:40:03,549 - __main__ - INFO - Client 2: Loaded global model
2025-04-21 17:40:03,553 - __main__ - INFO - Client 2: Starting training
2025-04-21 17:40:03,555 - __main__ - INFO - Client 2: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:40:04,723 - utils - INFO - Partition 20/20: Using 179 of 3694 samples from preprocessed_data\client_3
2025-04-21 17:40:04,724 - utils - INFO - Found 179 valid images in preprocessed_data\client_3
2025-04-21 17:40:04,724 - utils - INFO - Loaded DataLoader from preprocessed_data\client_3 with 179 samples
2025-04-21 17:40:04,728 - __main__ - INFO - Client 3: Downloading global model
2025-04-21 17:40:05,859 - __main__ - INFO - Client 0: Completed epoch 1 with 22 batches
2025-04-21 17:40:05,860 - __main__ - INFO - Client 0: Epoch 2/10
2025-04-21 17:40:06,174 - __main__ - INFO - Starting client 4 for round 20
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:40:07,207 - __main__ - INFO - Client 3: Loaded global model
2025-04-21 17:40:07,211 - __main__ - INFO - Client 3: Starting training
2025-04-21 17:40:07,212 - __main__ - INFO - Client 3: Epoch 1/10
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:40:07,278 - utils - INFO - Partition 20/20: Using 182 of 3697 samples from preprocessed_data\client_4
2025-04-21 17:40:07,278 - utils - INFO - Found 182 valid images in preprocessed_data\client_4
2025-04-21 17:40:07,279 - utils - INFO - Loaded DataLoader from preprocessed_data\client_4 with 182 samples
2025-04-21 17:40:07,283 - __main__ - INFO - Client 4: Downloading global model
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:40:09,899 - __main__ - INFO - Client 4: Loaded global model
2025-04-21 17:40:09,904 - __main__ - INFO - Client 4: Starting training
2025-04-21 17:40:09,906 - __main__ - INFO - Client 4: Epoch 1/10
D:\Projects\FLVM\client.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
D:\Projects\FLVM\venv\Lib\site-packages\torch\amp\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. 
Disabling
  warnings.warn(
2025-04-21 17:40:10,438 - __main__ - INFO - Client 1: Completed epoch 1 with 22 batches
2025-04-21 17:40:10,440 - __main__ - INFO - Client 1: Epoch 2/10
2025-04-21 17:40:15,043 - __main__ - INFO - Client 2: Completed epoch 1 with 21 batches
2025-04-21 17:40:15,044 - __main__ - INFO - Client 2: Epoch 2/10
2025-04-21 17:40:19,622 - __main__ - INFO - Client 0: Completed epoch 2 with 22 batches
2025-04-21 17:40:19,623 - __main__ - INFO - Client 0: Epoch 3/10
2025-04-21 17:40:22,015 - __main__ - INFO - Client 3: Completed epoch 1 with 23 batches
2025-04-21 17:40:22,017 - __main__ - INFO - Client 3: Epoch 2/10
2025-04-21 17:40:24,773 - __main__ - INFO - Client 1: Completed epoch 2 with 22 batches
2025-04-21 17:40:24,774 - __main__ - INFO - Client 1: Epoch 3/10
2025-04-21 17:40:27,596 - __main__ - INFO - Client 4: Completed epoch 1 with 23 batches
2025-04-21 17:40:27,598 - __main__ - INFO - Client 4: Epoch 2/10
2025-04-21 17:40:29,130 - __main__ - INFO - Client 2: Completed epoch 2 with 21 batches
2025-04-21 17:40:29,132 - __main__ - INFO - Client 2: Epoch 3/10
2025-04-21 17:40:34,985 - __main__ - INFO - Client 0: Completed epoch 3 with 22 batches
2025-04-21 17:40:34,988 - __main__ - INFO - Client 0: Epoch 4/10
2025-04-21 17:40:37,262 - __main__ - INFO - Client 3: Completed epoch 2 with 23 batches
2025-04-21 17:40:37,264 - __main__ - INFO - Client 3: Epoch 3/10
2025-04-21 17:40:39,178 - __main__ - INFO - Client 1: Completed epoch 3 with 22 batches
2025-04-21 17:40:39,178 - __main__ - INFO - Client 1: Epoch 4/10
2025-04-21 17:40:42,790 - __main__ - INFO - Client 4: Completed epoch 2 with 23 batches
2025-04-21 17:40:42,791 - __main__ - INFO - Client 4: Epoch 3/10
2025-04-21 17:40:43,070 - __main__ - INFO - Client 2: Completed epoch 3 with 21 batches
2025-04-21 17:40:43,071 - __main__ - INFO - Client 2: Epoch 4/10
2025-04-21 17:40:50,366 - __main__ - INFO - Client 0: Completed epoch 4 with 22 batches
2025-04-21 17:40:50,366 - __main__ - INFO - Client 0: Epoch 5/10
2025-04-21 17:40:52,353 - __main__ - INFO - Client 3: Completed epoch 3 with 23 batches
2025-04-21 17:40:52,355 - __main__ - INFO - Client 3: Epoch 4/10
2025-04-21 17:40:53,360 - __main__ - INFO - Client 1: Completed epoch 4 with 22 batches
2025-04-21 17:40:53,361 - __main__ - INFO - Client 1: Epoch 5/10
2025-04-21 17:40:56,884 - __main__ - INFO - Client 2: Completed epoch 4 with 21 batches
2025-04-21 17:40:56,885 - __main__ - INFO - Client 2: Epoch 5/10
2025-04-21 17:40:58,113 - __main__ - INFO - Client 4: Completed epoch 3 with 23 batches
2025-04-21 17:40:58,114 - __main__ - INFO - Client 4: Epoch 4/10
2025-04-21 17:41:05,709 - __main__ - INFO - Client 0: Completed epoch 5 with 22 batches
2025-04-21 17:41:05,709 - __main__ - INFO - Client 0: Epoch 6/10
2025-04-21 17:41:07,212 - __main__ - INFO - Client 3: Completed epoch 4 with 23 batches
2025-04-21 17:41:07,213 - __main__ - INFO - Client 3: Epoch 5/10
2025-04-21 17:41:07,783 - __main__ - INFO - Client 1: Completed epoch 5 with 22 batches
2025-04-21 17:41:07,784 - __main__ - INFO - Client 1: Epoch 6/10
2025-04-21 17:41:10,501 - __main__ - INFO - Client 2: Completed epoch 5 with 21 batches
2025-04-21 17:41:10,501 - __main__ - INFO - Client 2: Epoch 6/10
2025-04-21 17:41:13,042 - __main__ - INFO - Client 4: Completed epoch 4 with 23 batches
2025-04-21 17:41:13,043 - __main__ - INFO - Client 4: Epoch 5/10
2025-04-21 17:41:21,456 - __main__ - INFO - Client 0: Completed epoch 6 with 22 batches
2025-04-21 17:41:21,456 - __main__ - INFO - Client 0: Epoch 7/10
2025-04-21 17:41:22,064 - __main__ - INFO - Client 3: Completed epoch 5 with 23 batches
2025-04-21 17:41:22,065 - __main__ - INFO - Client 3: Epoch 6/10
2025-04-21 17:41:22,183 - __main__ - INFO - Client 1: Completed epoch 6 with 22 batches
2025-04-21 17:41:22,184 - __main__ - INFO - Client 1: Epoch 7/10
2025-04-21 17:41:24,117 - __main__ - INFO - Client 2: Completed epoch 6 with 21 batches
2025-04-21 17:41:24,117 - __main__ - INFO - Client 2: Epoch 7/10
2025-04-21 17:41:28,174 - __main__ - INFO - Client 4: Completed epoch 5 with 23 batches
2025-04-21 17:41:28,174 - __main__ - INFO - Client 4: Epoch 6/10
2025-04-21 17:41:36,384 - __main__ - INFO - Client 1: Completed epoch 7 with 22 batches
2025-04-21 17:41:36,385 - __main__ - INFO - Client 1: Epoch 8/10
2025-04-21 17:41:36,866 - __main__ - INFO - Client 0: Completed epoch 7 with 22 batches
2025-04-21 17:41:36,867 - __main__ - INFO - Client 0: Epoch 8/10
2025-04-21 17:41:36,995 - __main__ - INFO - Client 3: Completed epoch 6 with 23 batches
2025-04-21 17:41:36,996 - __main__ - INFO - Client 3: Epoch 7/10
2025-04-21 17:41:37,860 - __main__ - INFO - Client 2: Completed epoch 7 with 21 batches
2025-04-21 17:41:37,861 - __main__ - INFO - Client 2: Epoch 8/10
2025-04-21 17:41:43,462 - __main__ - INFO - Client 4: Completed epoch 6 with 23 batches
2025-04-21 17:41:43,462 - __main__ - INFO - Client 4: Epoch 7/10
2025-04-21 17:41:50,719 - __main__ - INFO - Client 1: Completed epoch 8 with 22 batches
2025-04-21 17:41:50,721 - __main__ - INFO - Client 1: Epoch 9/10
2025-04-21 17:41:51,975 - __main__ - INFO - Client 3: Completed epoch 7 with 23 batches
2025-04-21 17:41:51,976 - __main__ - INFO - Client 3: Epoch 8/10
2025-04-21 17:41:52,021 - __main__ - INFO - Client 2: Completed epoch 8 with 21 batches
2025-04-21 17:41:52,021 - __main__ - INFO - Client 2: Epoch 9/10
2025-04-21 17:41:52,346 - __main__ - INFO - Client 0: Completed epoch 8 with 22 batches
2025-04-21 17:41:52,347 - __main__ - INFO - Client 0: Epoch 9/10
2025-04-21 17:41:58,758 - __main__ - INFO - Client 4: Completed epoch 7 with 23 batches
2025-04-21 17:41:58,759 - __main__ - INFO - Client 4: Epoch 8/10
2025-04-21 17:42:04,741 - __main__ - INFO - Client 1: Completed epoch 9 with 22 batches
2025-04-21 17:42:04,742 - __main__ - INFO - Client 1: Epoch 10/10
2025-04-21 17:42:05,599 - __main__ - INFO - Client 2: Completed epoch 9 with 21 batches
2025-04-21 17:42:05,600 - __main__ - INFO - Client 2: Epoch 10/10
2025-04-21 17:42:06,186 - __main__ - INFO - Client 1: Reached maximum of 200 batches in epoch 10
2025-04-21 17:42:06,186 - __main__ - INFO - Client 1: Completed epoch 10 with 2 batches
2025-04-21 17:42:06,186 - __main__ - INFO - Client 1: Finished training with 200 total batches
2025-04-21 17:42:06,187 - __main__ - INFO - Client 1: Saving and sending weights
2025-04-21 17:42:06,588 - __main__ - INFO - Client 3: Completed epoch 8 with 23 batches
2025-04-21 17:42:06,589 - __main__ - INFO - Client 3: Epoch 9/10
2025-04-21 17:42:07,576 - __main__ - INFO - Client 0: Completed epoch 9 with 22 batches
2025-04-21 17:42:07,577 - __main__ - INFO - Client 0: Epoch 10/10
2025-04-21 17:42:08,831 - __main__ - INFO - Client 0: Reached maximum of 200 batches in epoch 10
2025-04-21 17:42:08,831 - __main__ - INFO - Client 0: Completed epoch 10 with 2 batches
2025-04-21 17:42:08,832 - __main__ - INFO - Client 0: Finished training with 200 total batches
2025-04-21 17:42:08,833 - __main__ - INFO - Client 0: Saving and sending weights
2025-04-21 17:42:08,921 - __main__ - INFO - Client 1: Weights sent to server
2025-04-21 17:42:11,084 - __main__ - INFO - Client 2: Reached maximum of 200 batches in epoch 10
2025-04-21 17:42:11,085 - __main__ - INFO - Client 2: Completed epoch 10 with 11 batches
2025-04-21 17:42:11,085 - __main__ - INFO - Client 2: Finished training with 200 total batches
2025-04-21 17:42:11,085 - __main__ - INFO - Client 2: Saving and sending weights
2025-04-21 17:42:11,513 - __main__ - INFO - Client 0: Weights sent to server
2025-04-21 17:42:11,614 - __main__ - INFO - Client 4: Completed epoch 8 with 23 batches
2025-04-21 17:42:11,614 - __main__ - INFO - Client 4: Epoch 9/10
2025-04-21 17:42:13,093 - __main__ - INFO - Client 3: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:13,093 - __main__ - INFO - Client 3: Completed epoch 9 with 16 batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Reached maximum of 200 batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:42:14,070 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:42:11,614 - __main__ - INFO - Client 4: Epoch 9/10
2025-04-21 17:42:13,093 - __main__ - INFO - Client 3: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:13,093 - __main__ - INFO - Client 3: Completed epoch 9 with 16 batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Reached maximum of 200 batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:42:14,070 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:13,093 - __main__ - INFO - Client 3: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:13,093 - __main__ - INFO - Client 3: Completed epoch 9 with 16 batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Reached maximum of 200 batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:42:14,070 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Finished training with 200 total batches
2025-04-21 17:42:13,094 - __main__ - INFO - Client 3: Saving and sending weights
2025-04-21 17:42:14,070 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:14,070 - __main__ - INFO - Client 2: Weights sent to server
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches in epoch 9
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Completed epoch 9 with 16 batches
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Completed epoch 9 with 16 batches
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Finished training with 200 total batches
2025-04-21 17:42:15,458 - __main__ - INFO - Client 4: Saving and sending weights
2025-04-21 17:42:15,753 - __main__ - INFO - Client 3: Weights sent to server
2025-04-21 17:42:17,729 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Reached maximum of 200 batches
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Finished training with 200 total batches
2025-04-21 17:42:15,458 - __main__ - INFO - Client 4: Saving and sending weights
2025-04-21 17:42:15,753 - __main__ - INFO - Client 3: Weights sent to server
2025-04-21 17:42:17,729 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:42:15,457 - __main__ - INFO - Client 4: Finished training with 200 total batches
2025-04-21 17:42:15,458 - __main__ - INFO - Client 4: Saving and sending weights
2025-04-21 17:42:15,753 - __main__ - INFO - Client 3: Weights sent to server
2025-04-21 17:42:17,729 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:42:21,629 - __main__ - INFO - Starting nightly aggregation...
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
2025-04-21 17:42:17,729 - __main__ - INFO - Client 4: Weights sent to server
2025-04-21 17:42:21,629 - __main__ - INFO - Starting nightly aggregation...
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
2025-04-21 17:42:21,629 - __main__ - INFO - Starting nightly aggregation...
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
D:\Projects\FLVM\venv\Lib\site-packages\transformers\modeling_utils.py:4056: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
  warnings.warn(
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
Some weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
ias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:42:22,718 - __main__ - INFO - Found 5 client weights for aggregation
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-04-21 17:42:22,718 - __main__ - INFO - Found 5 client weights for aggregation
2025-04-21 17:42:29,127 - __main__ - INFO - Processed weights from weights_0_20250421_174211.h5 with 173 samples
2025-04-21 17:42:22,718 - __main__ - INFO - Found 5 client weights for aggregation
2025-04-21 17:42:29,127 - __main__ - INFO - Processed weights from weights_0_20250421_174211.h5 with 173 samples
2025-04-21 17:42:29,127 - __main__ - INFO - Processed weights from weights_0_20250421_174211.h5 with 173 samples
2025-04-21 17:42:29,134 - __main__ - INFO - Processed weights from weights_1_20250421_174208.h5 with 170 samples
2025-04-21 17:42:29,134 - __main__ - INFO - Processed weights from weights_1_20250421_174208.h5 with 170 samples
2025-04-21 17:42:29,142 - __main__ - INFO - Processed weights from weights_2_20250421_174214.h5 with 167 samples
2025-04-21 17:42:29,149 - __main__ - INFO - Processed weights from weights_3_20250421_174215.h5 with 179 samples
2025-04-21 17:42:29,157 - __main__ - INFO - Processed weights from weights_4_20250421_174217.h5 with 182 samples
2025-04-21 17:42:29,265 - __main__ - INFO - Aggregated and saved global model to global_model.h5
2025-04-21 17:42:29,267 - __main__ - INFO - Archived processed weight files
Validation: {'loss': 3.6124401244272666, 'accuracy':  